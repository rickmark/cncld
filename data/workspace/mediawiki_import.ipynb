{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T22:42:16.125618Z",
     "start_time": "2025-12-25T22:42:06.042234Z"
    }
   },
   "cell_type": "code",
   "source": "! pip install presto-python-client pandas numpy sqlalchemy ollama pydantic tqdm ipywidgets wikipyedia-md mysql-connector-python",
   "id": "a6ba7bb0ef9857ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting presto-python-client\r\n",
      "  Using cached presto_python_client-0.8.4-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Collecting pandas\r\n",
      "  Using cached pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\r\n",
      "Collecting numpy\r\n",
      "  Using cached numpy-2.4.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Collecting sqlalchemy\r\n",
      "  Using cached sqlalchemy-2.0.45-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Collecting ollama\r\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting pydantic\r\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\r\n",
      "Collecting tqdm\r\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting ipywidgets\r\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting wikipyedia-md\r\n",
      "  Downloading wikipyedia_md-0.1.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting mysql-connector-python\r\n",
      "  Using cached mysql_connector_python-9.5.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (7.5 kB)\r\n",
      "Collecting click (from presto-python-client)\r\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting requests (from presto-python-client)\r\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: six in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from presto-python-client) (1.17.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Collecting pytz>=2020.1 (from pandas)\r\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas)\r\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy)\r\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting httpx>=0.27 (from ollama)\r\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\r\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.41.5 (from pydantic)\r\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\r\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic)\r\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipywidgets) (0.2.3)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipywidgets) (9.8.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\r\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\r\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\r\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from wikipyedia-md)\r\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4<5.0.0,>=4.12.2->wikipyedia-md)\r\n",
      "  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting anyio (from httpx>=0.27->ollama)\r\n",
      "  Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting certifi (from httpx>=0.27->ollama)\r\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting httpcore==1.* (from httpx>=0.27->ollama)\r\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting idna (from httpx>=0.27->ollama)\r\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27->ollama)\r\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\r\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\r\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\r\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\r\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\r\n",
      "Collecting charset_normalizer<4,>=2 (from requests->presto-python-client)\r\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->presto-python-client)\r\n",
      "  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/anaconda3/envs/cncld/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\r\n",
      "Downloading presto_python_client-0.8.4-py3-none-any.whl (23 kB)\r\n",
      "Downloading pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.7/10.7 MB\u001B[0m \u001B[31m12.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading numpy-2.4.0-cp313-cp313-macosx_14_0_arm64.whl (5.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.2/5.2 MB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached sqlalchemy-2.0.45-py3-none-any.whl (1.9 MB)\r\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\r\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\r\n",
      "Using cached pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\r\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\r\n",
      "Downloading wikipyedia_md-0.1.0-py3-none-any.whl (5.1 kB)\r\n",
      "Using cached mysql_connector_python-9.5.0-cp313-cp313-macosx_14_0_arm64.whl (17.6 MB)\r\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\r\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\r\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\r\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m914.9/914.9 kB\u001B[0m \u001B[31m11.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\r\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\r\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\r\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\r\n",
      "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached click-8.3.1-py3-none-any.whl (108 kB)\r\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\r\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\r\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\r\n",
      "Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\r\n",
      "Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)\r\n",
      "Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\r\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\r\n",
      "Installing collected packages: pytz, widgetsnbextension, urllib3, tzdata, typing-extensions, tqdm, soupsieve, numpy, mysql-connector-python, jupyterlab_widgets, idna, h11, click, charset_normalizer, certifi, annotated-types, typing-inspection, sqlalchemy, requests, pydantic-core, pandas, httpcore, beautifulsoup4, anyio, wikipyedia-md, pydantic, presto-python-client, ipywidgets, httpx, ollama\r\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.0 beautifulsoup4-4.14.3 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 mysql-connector-python-9.5.0 numpy-2.4.0 ollama-0.6.1 pandas-2.3.3 presto-python-client-0.8.4 pydantic-2.12.5 pydantic-core-2.41.5 pytz-2025.2 requests-2.32.5 soupsieve-2.8.1 sqlalchemy-2.0.45 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 widgetsnbextension-4.0.15 wikipyedia-md-0.1.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T06:40:28.980489Z",
     "start_time": "2025-12-25T06:40:28.973841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import ollama\n",
    "import pydantic\n",
    "import dataclasses\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "DATABASE_URL = 'mysql://root@localhost:3306/wikipedia'\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), './ext/')\n",
    "\n",
    "INDEX_FILE = [ name for name in glob.glob(os.path.join(DATA_PATH, '*.txt')) if 'multistream-index' in name ][0]\n",
    "\n",
    "tqdm.tqdm.pandas()"
   ],
   "id": "efd6ad8103cae027",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "SqlCellData": {
     "data_source_name": "wikipedia",
     "variableName$1": "df_sql1"
    },
    "ExecuteTime": {
     "end_time": "2025-12-25T06:40:28.993862Z",
     "start_time": "2025-12-25T06:40:28.981134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS multistream_index (\n",
    "    page_id bigint NOT NULL,\n",
    "    stream_offset bigint NOT NULL,\n",
    "    title text NOT NULL,\n",
    "    PRIMARY KEY (page_id),\n",
    "    INDEX (title),\n",
    "    FOREIGN KEY (page_id) REFERENCES page(page_id)\n",
    ");"
   ],
   "id": "8cd8fc371bdc0c52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Count]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "SqlCellData": {
     "data_source_name": "wikipedia",
     "variableName$1": "df_sql2"
    },
    "ExecuteTime": {
     "end_time": "2025-12-25T06:40:29.142403Z",
     "start_time": "2025-12-25T06:40:29.012129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS multistream_data (\n",
    "    page_id bigint NOT NULL,\n",
    "    body longtext NOT NULL,\n",
    "    markdown_text longtext NOT NULL,\n",
    "    PRIMARY KEY (page_id),\n",
    "    FOREIGN KEY (page_id) REFERENCES page(page_id)\n",
    ");"
   ],
   "id": "556d85cdd1e5f45a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "SqlCellData": {
     "data_source_name": "wikipedia",
     "variableName$1": "df_sql3"
    },
    "ExecuteTime": {
     "end_time": "2025-12-25T06:40:29.247213Z",
     "start_time": "2025-12-25T06:40:29.221619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS target_entities (\n",
    "    page_id bigint NOT NULL,\n",
    "    entity_type int NOT NULL,\n",
    "    PRIMARY KEY (page_id),\n",
    "    FOREIGN KEY (page_id) REFERENCES page(page_id)\n",
    ");"
   ],
   "id": "f125d66dc1c5681c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "SqlCellData": {
     "data_source_name": "wikipedia",
     "variableName$1": "df_sql4"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS target_news_entries (\n",
    "    id bigint NOT NULL AUTO_INCREMENT,\n",
    "    page_id bigint NOT NULL,\n",
    "    url text NOT NULL,\n",
    "    title text NOT NULL,\n",
    "    full_text longtext NOT NULL,\n",
    "    markdown_text longtext NOT NULL,\n",
    "    PRIMARY KEY (id),\n",
    "    INDEX (page_id),\n",
    "    FOREIGN KEY (page_id) REFERENCES page(page_id)\n",
    ")"
   ],
   "id": "b6930babc62790ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T06:41:00.962561Z",
     "start_time": "2025-12-25T06:40:29.263997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(INDEX_FILE, 'r') as index:\n",
    "    lines = [ row for row in [ line.split(':', maxsplit=3) for line in index.readlines() ] if len(row) == 3 ]\n",
    "    INDEX_ROWS = pd.DataFrame(lines, columns=['stream_offset', 'page_id', 'title'])"
   ],
   "id": "68230f442367386d",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T06:42:02.962538Z",
     "start_time": "2025-12-25T06:41:00.967809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "engine = create_engine(DATABASE_URL)\n",
    "INDEX_ROWS.to_sql('multistream_index', engine, if_exists='replace', index=False, chunksize=5000)"
   ],
   "id": "319ba56fdbb50c14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18636547"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T06:42:02.987260Z",
     "start_time": "2025-12-25T06:42:02.981379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclasses.dataclass\n",
    "class InferenceContext:\n",
    "    page_id: int\n",
    "    page_title: str\n",
    "    page_type: str\n",
    "    recent_news: list[str]\n",
    "    wikipedia_body: str\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.page_title}\\n\\n{self.wikipedia_body}\\n\\n# Recent News:\\n{'\\n'.join(self.recent_news)}\"\n",
    "\n",
    "class CancelInferenceResult(pydantic.BaseModel):\n",
    "    is_toxic: bool\n",
    "    revocable: bool\n",
    "    rationale: str\n",
    "    penance: str | None\n",
    "\n",
    "@dataclasses.dataclass()\n",
    "class CancelResult:\n",
    "    context: InferenceContext\n",
    "    result: CancelInferenceResult\n",
    "    confidence: float\n",
    "\n",
    "@dataclasses.dataclass()\n",
    "class Result:\n",
    "    page_id: int\n",
    "    page_title: str\n",
    "    page_type: str\n",
    "    result: bool\n",
    "    revocable: bool\n",
    "    confidence: float\n",
    "    rationale: str\n",
    "    penance: str | None\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a competent, reasonable, investigative journalist.  You are a supporter of LGBT rights and evaluate the subjects of your investigation for their toxicity to the LGBT community.  You do not exclude trans individuals from this definition.  You are fair and understand that people can change over time.  You provide thoughtful rationale to your opinions and also provide an explanation of what if anything the subject of the investigation could do to no longer be considered toxic to the LGBT community.\n",
    "\"\"\"\n",
    "\n",
    "TASK_PROMPT = \"\"\"\n",
    "# Task\n",
    "\n",
    "Given the following context, determine whether the subject of the investigation is toxic to the LGBT community.  Explain why you made this decision.  Determine whether the subject of the investigation can have this decision revoked.  Explain what steps would need to be taken to revoke this decision.\n",
    "\n",
    "# Context\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def process_input(input_context: InferenceContext) -> CancelResult:\n",
    "    response = ollama.chat(\n",
    "        model=\"llama4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": TASK_PROMPT + str(input_context)}\n",
    "        ],\n",
    "        logprobs=True,\n",
    "        format=CancelInferenceResult.model_json_schema()\n",
    "    )\n",
    "\n",
    "    parsed_response = CancelInferenceResult.model_validate_json(response.message.content)\n",
    "\n",
    "    return CancelResult(\n",
    "        context=input_context,\n",
    "        result=parsed_response,\n",
    "        confidence=math.exp(response.logprobs[6].logprob)\n",
    "    )\n",
    "\n",
    "def process_result(input_context: InferenceContext) -> Result:\n",
    "    inference_result = process_input(input_context)\n",
    "    return Result(\n",
    "        page_id=inference_result.context.page_id,\n",
    "        page_title=inference_result.context.page_title,\n",
    "        page_type=inference_result.context.page_type,\n",
    "        result=inference_result.result.is_toxic,\n",
    "        revocable=inference_result.result.revocable,\n",
    "        rationale=inference_result.result.rationale,\n",
    "        penance=inference_result.result.penance,\n",
    "        confidence=inference_result.confidence\n",
    "    )\n"
   ],
   "id": "839bf2e68deb8956",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T06:42:03.005212Z",
     "start_time": "2025-12-25T06:42:02.999773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_CONTEXTS = [\n",
    "    InferenceContext(\n",
    "        page_id=100,\n",
    "        page_title=\"Nicki Manaj\",\n",
    "        page_type=\"person\",\n",
    "        recent_news=[\"Nicki Manaj hates gays\"],\n",
    "        wikipedia_body=\"\"\"\n",
    "                       \"Onika Tanya Maraj-Petty (born December 8, 1982), known professionally as Nicki Minaj (/ˈnɪki mɪˈnɑːʒ/ ⓘ NIK-ee min-AHZH), is a Trinidadian rapper, singer, and songwriter based in the United States. Dubbed the \"Queen of Rap\" and one of the most influential rappers of all time, she is noted for her dynamic rap flow, witty lyrics, musical versatility, and alter egos, and is credited as a driving force in the mainstream resurgence of female rap since the 2010s. Raised in New York City, Minaj began rapping professionally in the early 2000s and gained recognition with her three mixtapes between 2007 and 2009.\"\"\"\n",
    "    )\n",
    "]"
   ],
   "id": "a20f618daad0ccb4",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T06:42:20.844635Z",
     "start_time": "2025-12-25T06:42:03.011870Z"
    }
   },
   "cell_type": "code",
   "source": "RESULTS = pd.DataFrame(map(process_result, tqdm.notebook.tqdm(INPUT_CONTEXTS)))",
   "id": "4a31ec9140b45271",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eedc0424abce408295ad9f22c8a51580"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T17:28:29.497468Z",
     "start_time": "2025-12-25T17:28:29.461048Z"
    }
   },
   "cell_type": "code",
   "source": "RESULTS",
   "id": "7112207384995db7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   page_id   page_title page_type  result  revocable  confidence  \\\n",
       "0      100  Nicki Manaj    person    True       True    0.297844   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  Nicki Minaj has expressed anti-LGBTQ+ views in...   \n",
       "\n",
       "                                             penance  \n",
       "0  To no longer be considered toxic to the LGBT c...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>page_type</th>\n",
       "      <th>result</th>\n",
       "      <th>revocable</th>\n",
       "      <th>confidence</th>\n",
       "      <th>rationale</th>\n",
       "      <th>penance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>Nicki Manaj</td>\n",
       "      <td>person</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.297844</td>\n",
       "      <td>Nicki Minaj has expressed anti-LGBTQ+ views in...</td>\n",
       "      <td>To no longer be considered toxic to the LGBT c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
